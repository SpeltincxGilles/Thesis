{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbec662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ðŸ”¹ You change this manually per model\n",
    "model_dir = r\"C:\\Users\\Gilles\\Documents\\school\\Ma2\\Thesis\\VSC\\IRIS\\Own_code\\results\\OrthoModel_Relu_Nobias\"\n",
    "\n",
    "# ðŸ”¹ Where you want the graphs saved (on your PC)\n",
    "save_dir = os.path.join(model_dir, \"graphs\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "metrics = [\n",
    "    \"final_train_loss\",\n",
    "    \"final_valid_loss\",\n",
    "    \"final_train_accuracy\",\n",
    "    \"final_valid_accuracy\",\n",
    "    \"epochs\",\n",
    "    \"epochs_to_final_train\",\n",
    "    \"epochs_to_final_valid\"\n",
    "]\n",
    "\n",
    "# --- LOAD ALL CSV FILES ---\n",
    "csv_files = [f for f in os.listdir(model_dir) if f.endswith(\".csv\")]\n",
    "\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    dfs.append(pd.read_csv(os.path.join(model_dir, file)))\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Convert hidden_sizes column to a consistent string format\n",
    "df[\"hidden_sizes\"] = df[\"hidden_sizes\"].astype(str)\n",
    "\n",
    "# --- SUMMARIZE PER ARCHITECTURE ---\n",
    "group = df.groupby(\"hidden_sizes\")\n",
    "\n",
    "summary = {}\n",
    "for key, df_run in group:\n",
    "    summary[key] = {}\n",
    "    for m in metrics:\n",
    "        summary[key][f\"{m}_mean\"] = df_run[m].mean()\n",
    "        summary[key][f\"{m}_std\"]  = df_run[m].std()\n",
    "\n",
    "summary_df = pd.DataFrame(summary).T  # Transpose for rows = architectures\n",
    "\n",
    "\n",
    "# --- PLOT 4Ã—4 GRID WITH HEATMAP AND MARGINAL AVG/STD ---\n",
    "layer_vals = [1,2,3,4]\n",
    "neuron_vals = [1,2,3,4]\n",
    "\n",
    "for metric in metrics:\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.set_xticks(range(4))\n",
    "    ax.set_yticks(range(4))\n",
    "    ax.set_xticklabels(neuron_vals)\n",
    "    ax.set_yticklabels(layer_vals)\n",
    "    ax.set_xlabel(\"Neurons per layer\")\n",
    "    ax.set_ylabel(\"Number of layers\")\n",
    "    ax.set_title(metric)\n",
    "    \n",
    "    data = np.zeros((len(layer_vals), len(neuron_vals)))\n",
    "    for i, neur in enumerate(neuron_vals):\n",
    "        for j, lay in enumerate(layer_vals):\n",
    "            arch = str([neur]*lay)\n",
    "            if arch in summary_df.index:\n",
    "                data[j, i] = summary_df.loc[arch, f\"{metric}_mean\"]\n",
    "            else:\n",
    "                data[j, i] = np.nan\n",
    "\n",
    "    # Heatmap\n",
    "    cmap = plt.cm.viridis\n",
    "    im = ax.imshow(data, origin='lower', cmap=cmap, interpolation='nearest',\n",
    "                   extent=(-0.5, len(neuron_vals)-0.5, -0.5, len(layer_vals)-0.5))\n",
    "\n",
    "    # Annotate squares\n",
    "    for i, neur in enumerate(neuron_vals):\n",
    "        for j, lay in enumerate(layer_vals):\n",
    "            arch = str([neur]*lay)\n",
    "            if arch in summary_df.index:\n",
    "                mean = summary_df.loc[arch, f\"{metric}_mean\"]\n",
    "                std  = summary_df.loc[arch, f\"{metric}_std\"]\n",
    "                ax.text(i, j, f\"{mean:.4f}\\nÂ±{std:.4f}\", ha='center', va='center', fontsize=9, color='white')\n",
    "            ax.add_patch(plt.Rectangle((i-0.5, j-0.5), 1, 1, fill=False))\n",
    "\n",
    "        # --- Row averages (per layer) ---\n",
    "    for j, lay in enumerate(layer_vals):\n",
    "        row_vals = []\n",
    "        for neur in neuron_vals:\n",
    "            arch = str([neur]*lay)\n",
    "            if arch in summary_df.index:\n",
    "                row_vals.append(summary_df.loc[arch, f\"{metric}_mean\"])\n",
    "            else:\n",
    "                row_vals.append(np.nan)\n",
    "        row_mean = np.nanmean(row_vals)\n",
    "        row_std  = np.nanstd(row_vals)\n",
    "        ax.text(len(neuron_vals)-0.2, j, f\"{row_mean:.4f}\\nÂ±{row_std:.4f}\", va='center', ha='left', fontsize=8, color='black')\n",
    "\n",
    "    # --- Column averages (per neuron) ---\n",
    "    for i, neur in enumerate(neuron_vals):\n",
    "        col_vals = []\n",
    "        for lay in layer_vals:\n",
    "            arch = str([neur]*lay)\n",
    "            if arch in summary_df.index:\n",
    "                col_vals.append(summary_df.loc[arch, f\"{metric}_mean\"])\n",
    "            else:\n",
    "                col_vals.append(np.nan)\n",
    "        col_mean = np.nanmean(col_vals)\n",
    "        col_std  = np.nanstd(col_vals)\n",
    "        ax.text(i, len(layer_vals)-0.2, f\"{col_mean:.4f}\\nÂ±{col_std:.4f}\", ha='center', va='bottom', fontsize=8, color='black')\n",
    "\n",
    "    ax.set_xlim(-0.5, len(neuron_vals)-0.5)\n",
    "    ax.set_ylim(-0.5, len(layer_vals)-0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f\"{metric}.png\"), dpi=300)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e6cb95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photonics_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
